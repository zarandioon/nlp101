{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "input_dir=\"data\"\n",
    "\n",
    "with open(input_dir + \"/mfcc/lang_feature_file.csv\",'r') as f:\n",
    "    ls = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "l=ls[0]\n",
    "r = l[0:-1].split(',',2)\n",
    "x = r[0]\n",
    "y = ast.literal_eval(r[2].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records: 400\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import random\n",
    "\n",
    "input_dir=\"data\"\n",
    "\n",
    "records = []\n",
    "\n",
    "with open(input_dir + \"/mfcc/lang_feature_file.csv\", 'r') as f:\n",
    "    for l in f:\n",
    "        r = l[0:-1].split(',',2)\n",
    "        records.append((r[0], r[1], ast.literal_eval(r[2].strip())))\n",
    "random.shuffle(records)\n",
    "print(\"records: %s\" % len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = sorted(list(set([r[0] for r in records])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_index = {l: i for i, l in enumerate(langs)}\n",
    "index_lang = {i: l for i, l in lang_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_n = 400 * 2 // 3\n",
    "train=records[0:t_n]\n",
    "valid=records[t_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o = [r[2][:100] for r in train]\n",
    "y_train_o = [lang_index[r[0]] for r in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_o = [r[2][:100] for r in valid]\n",
    "y_valid_o = [lang_index[r[0]] for r in valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o, y_train_o, x_valid_o, y_valid_o = map(\n",
    "    torch.tensor, (x_train_o, y_train_o, x_valid_o, y_valid_o)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_o.reshape(x_train_o.shape[0],-1)\n",
    "x_valid = x_valid_o.reshape(x_valid_o.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_o\n",
    "y_valid = y_valid_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([266, 1300])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x_train.shape[1]\n",
    "output_size = len(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 7, 641])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=64\n",
    "xb=x_train[0:bs]\n",
    "xb=xb.view(xb.shape[0],1,100 * 13)\n",
    "conv1 = nn.Conv1d(1, 20, kernel_size=13, stride=1, padding=0)\n",
    "xb = conv1(xb)\n",
    "xb=xb.view(xb.shape[0],1,20,1288)\n",
    "xb.shape\n",
    "conv2 = nn.Conv2d(1, 1, kernel_size=(5,5), stride=1, padding=0)\n",
    "xb=conv2(xb)\n",
    "m = nn.MaxPool2d(3, stride=2)\n",
    "xb = m(xb)\n",
    "#lin1 = nn.Linear(16 * 1284, 30)\n",
    "#xb = xb.view(bs, -1)\n",
    "#xb=lin1(xb)\n",
    "xb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN_(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 20, kernel_size=13, stride=1, padding=0)        \n",
    "        self.d1 = nn.Dropout(0.7)\n",
    "        self.conv2 = nn.Conv2d(1, 1, kernel_size=(5,5), stride=1, padding=0)\n",
    "        self.d2 = nn.Dropout(0.7)\n",
    "        self.m = nn.MaxPool2d(3, stride=2)\n",
    "        self.lin1 = nn.Linear(7* 641, 30)\n",
    "        self.d5 = nn.Dropout(0.6)\n",
    "        self.lin2 = nn.Linear(150, 30)\n",
    "        self.d6 = nn.Dropout(0.6)\n",
    "        self.lin3 = nn.Linear(30, 10)\n",
    "        self.d7 = nn.Dropout(0.8)\n",
    "        self.lin4 = nn.Linear(30, output_size)\n",
    "        self.d8 = nn.Dropout(0.8)\n",
    "    def forward(self, xb):\n",
    "        bs = xb.shape[0]\n",
    "        xb=xb.view(xb.shape[0],1,100 * 13)\n",
    "        xb = self.d1(self.conv1(xb))\n",
    "        xb=xb.view(xb.shape[0],1,20,1288)\n",
    "        xb = self.d2(self.conv2(xb))\n",
    "        xb = self.m(xb)\n",
    "        #xb = self.d3(self.conv3(xb))\n",
    "        #xb = self.d4(self.conv4(xb))\n",
    "        xb = xb.view(bs, -1)\n",
    "        xb = self.d5(F.relu(self.lin1(xb)))\n",
    "        #xb = self.d6(F.relu(self.lin2(xb)))\n",
    "        #xb = self.d7(F.relu(self.lin3(xb)))\n",
    "        xb = self.lin4(xb)\n",
    "        return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5, 99, 12])\n",
      "torch.Size([64, 5, 49, 5])\n",
      "torch.Size([64, 5, 12, 1])\n"
     ]
    }
   ],
   "source": [
    "s=100\n",
    "f=13\n",
    "c1=5\n",
    "bs=64\n",
    "xb=x_train[0:bs]\n",
    "xb=xb.view(xb.shape[0],1,100,13)\n",
    "conv1 = nn.Conv2d(1, 5, kernel_size=(2,2), stride=1, padding=0)\n",
    "xb1 = conv1(xb)\n",
    "print(xb1.shape)\n",
    "#xb1 = F.avg_pool2d(xb1, (2, 1))\n",
    "#print(xb1.shape)\n",
    "conv2 = nn.Conv2d(5, 5, kernel_size=(2,2), stride=2, padding=0, dilation=2)\n",
    "xb2 = conv2(xb1)\n",
    "print(xb2.shape)\n",
    "conv3 = nn.Conv2d(5, 5, kernel_size=(2,2), stride=4, padding=0, dilation=4)\n",
    "xb3 = conv3(xb2)\n",
    "print(xb3.shape)\n",
    "#conv4 = nn.Conv2d(1, 1, kernel_size=(10,1), stride=1, padding=0, dilation=1)\n",
    "#xb4 = conv4(xb3)\n",
    "#print(xb4.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 5, kernel_size=(2,2), stride=1, padding=0)\n",
    "        self.d1 = nn.Dropout(0.7)\n",
    "        self.conv2 = nn.Conv2d(5, 5, kernel_size=(2,2), stride=2, padding=0, dilation=2)\n",
    "        self.d2 = nn.Dropout(0.7)\n",
    "        self.conv3 = nn.Conv2d(5, 5, kernel_size=(2,2), stride=4, padding=0, dilation=4)\n",
    "        self.d3 = nn.Dropout(0.6)\n",
    "        self.conv4 = nn.Conv2d(1, 1, kernel_size=(10,1), stride=(1,1), padding=0, dilation=1)\n",
    "        self.d4 = nn.Dropout(0.6)\n",
    "        self.lin1 = nn.Linear(5 * 12 * 1, 30)\n",
    "        self.d5 = nn.Dropout(0.6)\n",
    "        self.lin2 = nn.Linear(150, 30)\n",
    "        self.d6 = nn.Dropout(0.6)\n",
    "        self.lin3 = nn.Linear(30, 10)\n",
    "        self.d7 = nn.Dropout(0.8)\n",
    "        self.lin4 = nn.Linear(30, output_size)\n",
    "        self.d8 = nn.Dropout(0.8)\n",
    "    def forward(self, xb):\n",
    "        bs = xb.shape[0]\n",
    "        xb = xb.view(-1, 1, 100, 13)\n",
    "        xb = self.d1(self.conv1(xb))\n",
    "        xb = self.d2(self.conv2(xb))\n",
    "        xb = self.d3(self.conv3(xb))\n",
    "        #xb = self.d4(self.conv4(xb))\n",
    "        xb = xb.view(bs, -1)\n",
    "        xb = self.d5(F.relu(self.lin1(xb)))\n",
    "        #xb = self.d6(F.relu(self.lin2(xb)))\n",
    "        #xb = self.d7(F.relu(self.lin3(xb)))\n",
    "        xb = self.lin4(xb)\n",
    "        return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.k1=4\n",
    "        self.c1=5\n",
    "        self.conv1 = nn.Conv2d(1, self.c1, kernel_size=(5,self.k1), stride=1, padding=0)\n",
    "        self.d0 = nn.Dropout(0.6)\n",
    "        self.conv2 = nn.Conv2d(self.c1, 1, kernel_size=(9,5), stride=1, padding=1)\n",
    "        self.d01 = nn.Dropout(0.6)\n",
    "        self.lin1 = nn.Linear(285, 50)\n",
    "        self.d1 = nn.Dropout(0.6)\n",
    "        self.lin2 = nn.Linear(50, 30)\n",
    "        self.d2 = nn.Dropout(0.6)\n",
    "        self.lin3 = nn.Linear(30, output_size)\n",
    "        #self.d3 = nn.Dropout(0.6)\n",
    "        #self.lin4 = nn.Linear(20, output_size)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        bs=xb.shape[0]\n",
    "        xb = xb.view(-1, 1, 13, 100)\n",
    "        xb = self.conv1(xb)\n",
    "        xb = self.d0(xb)\n",
    "        #print(xb.shape)\n",
    "        #print(xb.shape)\n",
    "        xb = self.conv2(xb)\n",
    "        #print(xb.shape)\n",
    "        #xb = F.avg_pool2d(xb, (self.c1, 1))\n",
    "\n",
    "        #print(input_size)\n",
    "        #print(self.c1 * (input_size//13 - self.k1 + 1))\n",
    "        xb = xb.view(bs, -1)\n",
    "        #print(xb.shape)\n",
    "        xb = F.relu(self.lin1(xb))\n",
    "        #xb = self.d1(xb)\n",
    "        #xb = F.relu(self.lin2(xb))\n",
    "        #xb = self.d2(xb)\n",
    "        #xb = self.lin3(xb)\n",
    "        return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "lr = 0.0005 # 0.0001 # \n",
    "def get_model():\n",
    "    model = Mnist_CNN() #Mnist_MLP() #Mnist_Logistic() #Mnist_MLP()\n",
    "    return model, optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid acc increased to tensor(0.2985)\n",
      "valid acc increased to tensor(0.3060)\n",
      "valid acc increased to tensor(0.3134)\n",
      "best valid acc tensor(0.3134)\n",
      "train acc tensor(0.2744)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "n = x_train.shape[0]\n",
    "bs = 64  # batch size\n",
    "\n",
    "epochs = 500  # how many epochs to train for\n",
    "best_valid_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i in range((n - 1) // bs + 1): # for all minibatches (n number of training datapoints)\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_acc = accuracy(model(x_valid), y_valid)\n",
    "        if valid_acc > best_valid_acc:\n",
    "            best_valid_acc = valid_acc\n",
    "            print(\"valid acc increased to %s\" % valid_acc) \n",
    "        else:\n",
    "            if  valid_acc / best_valid_acc < 0.7:\n",
    "                print(\"valid acc deccreased to %s\" % valid_acc) \n",
    "                #break\n",
    "    #print(\"epoch: %s\" % epoch)\n",
    "print(\"best valid acc %s\" % best_valid_acc)\n",
    "model.eval()\n",
    "train_acc = accuracy(model(x_train), y_train)\n",
    "print(\"train acc %s\" % train_acc) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
